{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoders: Binary Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Note on the data set \n",
    "The data set used here is not particularly complex and/or big. It's not really all that challenging to find the fraud. In an ideal world we'd be using more complex data sets to show the real power of Deep Learning. There are a bunch of PCA'ed data sets available, but the PCA obfuscates some of the elements that are useful. \n",
    "*These examples are meant to show the possibilities, it's not so useful to interpret their performance on this data set*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import d373c7.features as ft\n",
    "import d373c7.engines as en\n",
    "import d373c7.pytorch as pt\n",
    "import d373c7.pytorch.models as pm\n",
    "import d373c7.plot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version : 1.6.0\n",
      "Cuda Version  : 10.2\n",
      "GPU found. Using GPU <0>\n"
     ]
    }
   ],
   "source": [
    "print(f'Torch Version : {torch.__version__}')\n",
    "\n",
    "# Set up the GPU if available. This will be the default device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(f'Cuda Version  : {torch.version.cuda}')\n",
    "    print(f'GPU found. Using GPU <{device.index}>')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f'No GPU found ... Using CPU {device}')\n",
    "\n",
    "# Also set up a cpu device\n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set a random seed for Numpy and Torch\n",
    "> Will make sure we always sample in the same way. Makes it easier to compare results. At some point it should been removed to test the model stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "np.random.seed(42)\n",
    "# Torch\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define base feature and read the File\n",
    "The base features are features found in the input file. They need to be defined after which the file can be read using the `EnginePandasNumpy`. Using the `from_csv` method.\n",
    "The `from_csv` method will read the file and return a Pandas DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to read from another location\n",
    "file = '../../../data/bs140513_032310.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-03 14:40:22.364 d373c7.engines.common          INFO     Start Engine...\n",
      "2020-11-03 14:40:22.364 d373c7.engines.panda_numpy     INFO     Pandas Version : 1.1.2\n",
      "2020-11-03 14:40:22.365 d373c7.engines.panda_numpy     INFO     Numpy Version : 1.19.2\n",
      "2020-11-03 14:40:22.371 d373c7.engines.panda_numpy     INFO     Building Panda for : base from file ../../../data/bs140513_032310.csv\n",
      "2020-11-03 14:40:22.586 d373c7.engines.panda_numpy     INFO     Building Panda for : <base> from DataFrame. Inference mode <False>\n",
      "2020-11-03 14:40:22.592 d373c7.engines.panda_numpy     INFO     Done creating base. Shape=(594643, 6)\n",
      "2020-11-03 14:40:22.592 d373c7.engines.panda_numpy     INFO     Building Panda for : <learning> from DataFrame. Inference mode <False>\n",
      "2020-11-03 14:40:22.634 d373c7.engines.panda_numpy     INFO     Done creating learning. Shape=(594643, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_index</th>\n",
       "      <th>gender_index</th>\n",
       "      <th>merchant_index</th>\n",
       "      <th>category_index</th>\n",
       "      <th>amount_bin</th>\n",
       "      <th>fraud_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594638</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594639</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594640</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594641</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594642</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594643 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age_index  gender_index  merchant_index  category_index amount_bin  \\\n",
       "0               1             1               1               1          1   \n",
       "1               2             1               1               1          1   \n",
       "2               1             2               2               1          1   \n",
       "3               3             1               1               1          1   \n",
       "4               4             1               1               1          1   \n",
       "...           ...           ...             ...             ...        ...   \n",
       "594638          3             2               2               1          1   \n",
       "594639          1             2               2               1          1   \n",
       "594640          2             2              15              11          1   \n",
       "594641          4             1               2               1          1   \n",
       "594642          1             2               2               1          1   \n",
       "\n",
       "        fraud_label  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "594638            0  \n",
       "594639            0  \n",
       "594640            0  \n",
       "594641            0  \n",
       "594642            0  \n",
       "\n",
       "[594643 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = ft.FeatureSource('age', ft.FEATURE_TYPE_CATEGORICAL)\n",
    "gender = ft.FeatureSource('gender', ft.FEATURE_TYPE_CATEGORICAL)\n",
    "merchant = ft.FeatureSource('merchant', ft.FEATURE_TYPE_CATEGORICAL)\n",
    "category = ft.FeatureSource('category', ft.FEATURE_TYPE_CATEGORICAL)\n",
    "amount = ft.FeatureSource('amount', ft.FEATURE_TYPE_FLOAT)\n",
    "fraud = ft.FeatureSource('fraud', ft.FEATURE_TYPE_INT_8)\n",
    "\n",
    "base_features = ft.TensorDefinition(\n",
    "    'base', \n",
    "    [\n",
    "        age,\n",
    "        gender,\n",
    "        merchant,\n",
    "        category,\n",
    "        amount,\n",
    "        fraud\n",
    "    ])\n",
    "\n",
    "\n",
    "age_i = ft.FeatureIndex('age_index', ft.FEATURE_TYPE_INT_8, age)\n",
    "gender_i = ft.FeatureIndex('gender_index', ft.FEATURE_TYPE_INT_8, gender)\n",
    "merchant_i = ft.FeatureIndex('merchant_index', ft.FEATURE_TYPE_INT_16, merchant)\n",
    "category_i = ft.FeatureIndex('category_index', ft.FEATURE_TYPE_INT_16, category)\n",
    "amount_binned = ft.FeatureBin('amount_bin', ft.FEATURE_TYPE_INT_16, amount, 30)\n",
    "fraud_label = ft.FeatureLabelBinary('fraud_label', fraud)\n",
    "\n",
    "learning_features = ft.TensorDefinition(\n",
    "    'learning', \n",
    "    [\n",
    "        age_i,\n",
    "        gender_i,\n",
    "        merchant_i,\n",
    "        category_i,\n",
    "        amount_binned,\n",
    "        fraud_label\n",
    "    ])\n",
    "\n",
    "with en.EnginePandasNumpy() as e:\n",
    "    df = e.from_csv(base_features, file, inference=False)\n",
    "    df = e.from_df(learning_features, df, inference=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-03 14:41:14.406 d373c7.engines.common          INFO     Start Engine...\n",
      "2020-11-03 14:41:14.406 d373c7.engines.panda_numpy     INFO     Pandas Version : 1.1.2\n",
      "2020-11-03 14:41:14.407 d373c7.engines.panda_numpy     INFO     Numpy Version : 1.19.2\n",
      "2020-11-03 14:41:14.407 d373c7.engines.panda_numpy     INFO     Converting DataFrame to Numpy of type: int16\n",
      "2020-11-03 14:41:14.407 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: Categorical\n",
      "2020-11-03 14:41:14.411 d373c7.engines.panda_numpy     INFO     Converting DataFrame to Numpy of type: int8\n",
      "2020-11-03 14:41:14.411 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: Label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(594643, 5), (594643,)]\n",
      "['int16', 'int8']\n"
     ]
    }
   ],
   "source": [
    "with en.EnginePandasNumpy() as e:\n",
    "    data_list = e.to_numpy_list(learning_features, df)\n",
    "print(data_list.shapes)\n",
    "print(data_list.dtype_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle the data\n",
    "Time split the data. For time series data it is very important to keep the order of the data. This split will start from the end and work it's way to the front of the data. This way the training, validation and test data are nicely colocated in time\n",
    "\n",
    "> 1. Split out a training-set of size `test_records`. This is used for model testing.\n",
    "> 2. Split out a validation-set of size `validation_records`. It will be used to monitor overfitting during training\n",
    "> 3. All the rest is considered training data.\n",
    "\n",
    "__Important__. For auto-encoders we perform a 4th step, all fraud records will be removed from the training and validation data. The auto-encoder will only see *non-fraud* records during training.\n",
    "> 4. Remove fraud from training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data shapes [(458847, 5), (458847,)]\n",
      "Validation Data shapes [(29670, 5), (29670,)]\n",
      "Test Data shapes [(100000, 5), (100000,)]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_records = 100000\n",
    "val_records  = 30000 \n",
    "\n",
    "train_data, val_data, test_data = data_list.split_time(val_records, test_records) \n",
    "\n",
    "# Filter. Only keep non-fraud records with label 0. \n",
    "train_data = train_data.filter_label(learning_features, 0)\n",
    "val_data = val_data.filter_label(learning_features, 0)\n",
    "\n",
    "print(f'Training Data shapes {train_data.shapes}')\n",
    "print(f'Validation Data shapes {val_data.shapes}')\n",
    "print(f'Test Data shapes {test_data.shapes}')\n",
    "del data_list\n",
    "gc.collect()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "\n",
    "> Define a __LinearToCategoryAutoEncoder__. As input it takes the size of the latent dimension. In this case *3*. And it takes a list of integers indicating the number and the size of the hidden dimensions. *We are defining it to have 1 hidden layer of size 16*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
