{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Net (RNN) w/Series Expression\n",
    "\n",
    "The previous example showed some improvements we can make, but there are always more things we can do to make it easier for the model to detect fraud. Here are a couple of things we can do;\n",
    "\n",
    "- Add more derived features. For instance the fact that we had a round amount gets lost because of scaling and binning. Such a features can be added with a `FeatureExpression` it only depends on a single transactions\n",
    "- Some derived features might depend on the series. For instance we could argue that the time between transactions is a notion that gets lost in the 'stacking' of the series, this can not be calculated with just one transaction, we need a set of them. We have a `FeatureExpressionSeries` to help with that. A `FeatureExpressionSeries` works similar to a regular `FeatureExpression` but is executed as the series are built. While the regular `FeatureExpression` is built prior to constructing the Series. The input to a `FeatureExpressionSeries` is the ordered set of transaction fields as DataFrame. This syntax may seem a bit awkward, but it allows us to run highly efficient vectorized code on the DataFrames, this takes a fraction of the time Python would need natively to loop over the elements.\n",
    "\n",
    "We will not use the round amount example as there are barely round amounts in the data-set, a bit unrealistic. But we'll add a date-delta and we'll use the scaled amount again rather than using a binned amount, so as to mix things up a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Note on the data set \n",
    "The data set used here is not particularly complex and/or big. It's not really all that challenging to find the fraud. In an ideal world we'd be using more complex data sets to show the real power of Deep Learning. There are a bunch of PCA'ed data sets available, but the PCA obfuscates some of the elements that are useful. \n",
    "*These examples are meant to show the possibilities, it's not so useful to interpret their performance on this data set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import gc\n",
    "\n",
    "import d373c7.features as ft\n",
    "import d373c7.engines as en\n",
    "import d373c7.pytorch as pt\n",
    "import d373c7.pytorch.models as pm\n",
    "import d373c7.plot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set a random seed for Numpy and Torch\n",
    "> Will make sure we always sample in the same way. Makes it easier to compare results. At some point it should been removed to test the model stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "np.random.seed(42)\n",
    "# Torch\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define base feature and read the File\n",
    "The base features are features found in the input file. They need to be defined after which the file can be read using the `EnginePandasNumpy`. Using the `from_csv` method.\n",
    "\n",
    "A new function had been adeed to calculate the time-delta between consequent payments for the same customer. It's input will be a Panda's DataFrame and it will output a normalized (to 190 days) time-delta. Remember that __normalizing__ the data is important for Neural Nets, it allows them to converge much faster.\n",
    "\n",
    "The new function is used in the `FeatureExpressionSeries` feature named __'date-time-delta'__.\n",
    "\n",
    "The Customer data has a similar shape as the previous example, we can see however that the series output is different. We now have 3 Numpy Arrays in the series list instead of 2 in the previous examples \n",
    "- The first Numpy in the seriers list is of type `int16` and had a Rank-3. The first dimension is the batch, the second dimension is the time and the third dimension are the 'category' and 'merchant' indexes.\n",
    "- The second Numpy in the series list is of type `float32` and has a Rank-3. The first dimension is the batch, the second dimension is the time and the third dimension are the scaled amount and time-delta respetively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to read from another location\n",
    "file = '../../../../data/bs140513_032310.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 10:47:49.527 d373c7.engines.common          INFO     Start Engine...\n",
      "2021-12-29 10:47:49.527 d373c7.engines.panda_numpy     INFO     Pandas Version : 1.1.4\n",
      "2021-12-29 10:47:49.528 d373c7.engines.panda_numpy     INFO     Numpy Version : 1.19.2\n",
      "2021-12-29 10:47:49.528 d373c7.engines.panda_numpy     INFO     Building Panda for : customer_learning from file ../../../../data/bs140513_032310.csv\n",
      "2021-12-29 10:47:49.659 d373c7.engines.panda_numpy     INFO     Building Panda for : <Source_Derive_Source> from DataFrame. Inference mode <False>\n",
      "2021-12-29 10:47:49.659 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: Source_Derive_Source\n",
      "2021-12-29 10:47:49.660 d373c7.engines.panda_numpy     INFO     Done creating Source_Derive_Source. Shape=(594643, 2)\n",
      "2021-12-29 10:47:49.671 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: customer_learning\n",
      "2021-12-29 10:47:49.672 d373c7.engines.panda_numpy     INFO     Building Panda for : InternalKeyTime from file ../../../../data/bs140513_032310.csv\n",
      "2021-12-29 10:47:49.854 d373c7.engines.panda_numpy     INFO     Building Panda for : <Source_Derive_Source> from DataFrame. Inference mode <False>\n",
      "2021-12-29 10:47:49.854 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: Source_Derive_Source\n",
      "2021-12-29 10:47:49.860 d373c7.engines.panda_numpy     INFO     Done creating Source_Derive_Source. Shape=(594643, 5)\n",
      "2021-12-29 10:47:49.862 d373c7.engines.panda_numpy     INFO     Create amount_scale Normalize/Scale amount. Min. 0.00 Max. 8329.96\n",
      "2021-12-29 10:47:50.188 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: InternalKeyTime\n",
      "2021-12-29 10:47:50.194 d373c7.engines.panda_numpy     INFO     Start creating stacked series for Target Tensor Definition <transaction_learning> using 8 process(es)\n",
      "2021-12-29 10:47:55.310 d373c7.engines.panda_numpy     INFO     Returning series of types ['int16', 'float32'].\n",
      "2021-12-29 10:47:55.310 d373c7.engines.panda_numpy     INFO     Done creating transaction_learning. Shapes=[(594643, 5, 2), (594643, 5, 2)]\n",
      "2021-12-29 10:47:55.312 d373c7.engines.panda_numpy     INFO     Building Panda for : label from file ../../../../data/bs140513_032310.csv\n",
      "2021-12-29 10:47:55.428 d373c7.engines.panda_numpy     INFO     Building Panda for : <Source_Derive_Source> from DataFrame. Inference mode <False>\n",
      "2021-12-29 10:47:55.428 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: Source_Derive_Source\n",
      "2021-12-29 10:47:55.430 d373c7.engines.panda_numpy     INFO     Done creating Source_Derive_Source. Shape=(594643, 1)\n",
      "2021-12-29 10:47:55.432 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: label\n",
      "2021-12-29 10:47:55.433 d373c7.engines.panda_numpy     INFO     Converting DataFrame to Numpy of type: int8\n",
      "2021-12-29 10:47:55.433 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: Categorical\n",
      "2021-12-29 10:47:55.434 d373c7.engines.panda_numpy     INFO     Converting DataFrame to Numpy of type: int8\n",
      "2021-12-29 10:47:55.434 d373c7.engines.panda_numpy     INFO     Reshaping DataFrame to: Label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer data Shapes\n",
      "[(594643, 2)]\n",
      "['int8']\n",
      "Series Shapes\n",
      "[(594643, 5, 2), (594643, 5, 2)]\n",
      "['int16', 'float32']\n",
      "Label Shapes\n",
      "[(594643,)]\n",
      "['int8']\n",
      "Numpy Shapes\n",
      "[(594643, 2), (594643, 5, 2), (594643, 5, 2), (594643,)]\n"
     ]
    }
   ],
   "source": [
    "# Base Features\n",
    "step = ft.FeatureSource('step', ft.FEATURE_TYPE_INT_16) \n",
    "customer = ft.FeatureSource('customer', ft.FEATURE_TYPE_STRING)\n",
    "age = ft.FeatureSource('age', ft.FEATURE_TYPE_CATEGORICAL)\n",
    "gender = ft.FeatureSource('gender', ft.FEATURE_TYPE_CATEGORICAL)\n",
    "merchant = ft.FeatureSource('merchant', ft.FEATURE_TYPE_CATEGORICAL)\n",
    "category = ft.FeatureSource('category', ft.FEATURE_TYPE_CATEGORICAL)\n",
    "amount = ft.FeatureSource('amount', ft.FEATURE_TYPE_FLOAT)\n",
    "fraud = ft.FeatureSource('fraud', ft.FEATURE_TYPE_INT_8)\n",
    "\n",
    "# Function to calculate the date and time from the step\n",
    "def step_to_date(step_count: int):\n",
    "    return dt.datetime(2020, 1, 1) + dt.timedelta(days=int(step_count))\n",
    "\n",
    "# Function to calculate the time difference between all rows and normalise\n",
    "def calc_delta(dates):\n",
    "    if isinstance(dates, pd.DataFrame):\n",
    "        res = dates.diff() / np.timedelta64(190, 'D')\n",
    "        res = res.fillna(0).abs()\n",
    "        return res\n",
    "    else:\n",
    "        # There was only 1 row\n",
    "        return 0\n",
    "\n",
    "# Derived Features\n",
    "date_time = ft.FeatureExpression('date', ft.FEATURE_TYPE_DATE_TIME, step_to_date, [step])\n",
    "date_time_delta = ft.FeatureExpressionSeries('delta', ft.FEATURE_TYPE_FLOAT_32, calc_delta, [date_time])\n",
    "age_i = ft.FeatureIndex('age_index', ft.FEATURE_TYPE_INT_8, age)\n",
    "gender_i = ft.FeatureIndex('gender_index', ft.FEATURE_TYPE_INT_8, gender)\n",
    "merchant_i = ft.FeatureIndex('merchant_index', ft.FEATURE_TYPE_INT_16, merchant)\n",
    "category_i = ft.FeatureIndex('category_index', ft.FEATURE_TYPE_INT_16, category)\n",
    "amount_scale = ft.FeatureNormalizeScale('amount_scale', ft.FEATURE_TYPE_FLOAT_32, amount)\n",
    "fraud_label = ft.FeatureLabelBinary('fraud_label', ft.FEATURE_TYPE_INT_8, fraud)\n",
    "\n",
    "cust_learn_features = ft.TensorDefinition(\n",
    "    'customer_learning', \n",
    "    [\n",
    "        age_i,\n",
    "        gender_i,\n",
    "    ])\n",
    "\n",
    "trx_learn_features = ft.TensorDefinition(\n",
    "    'transaction_learning', \n",
    "    [\n",
    "        customer,\n",
    "        merchant_i,\n",
    "        category_i,\n",
    "        amount_scale,\n",
    "        date_time_delta\n",
    "    ])\n",
    "\n",
    "\n",
    "label = ft.TensorDefinition('label', [fraud_label])\n",
    "\n",
    "model_features = ft.TensorDefinitionMulti([cust_learn_features, trx_learn_features, label])\n",
    "\n",
    "with en.EnginePandasNumpy(num_threads=8) as e:\n",
    "    cust_df     = e.from_csv(cust_learn_features, file, inference=False)\n",
    "    series_list = e.to_series_stacked(\n",
    "        trx_learn_features, file, key_feature=customer, time_feature=date_time, window=5, inference=False\n",
    "    )\n",
    "    lb_df       = e.from_csv(label, file, inference=False)\n",
    "    cust_list   = e.to_numpy_list(cust_learn_features, cust_df)\n",
    "    lb_np       = e.to_numpy_list(label, lb_df)\n",
    "    \n",
    "print('Customer data Shapes')\n",
    "print(cust_list.shapes)\n",
    "print(cust_list.dtype_names)\n",
    "print('Series Shapes')\n",
    "print(series_list.shapes)\n",
    "print(series_list.dtype_names)\n",
    "print('Label Shapes')\n",
    "print(lb_np.shapes)\n",
    "print(lb_np.dtype_names)\n",
    "\n",
    "data_list = en.NumpyList(cust_list.lists + series_list.lists + lb_np.lists)\n",
    "print('Numpy Shapes')\n",
    "print(data_list.shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End\n",
    "\n",
    "This notebook merely shows how to add a series feature. It turns out that is you add them, on this data, the models perform worse. It is not totally clear if the date is actually a usefull feature. The data might not be constructed in a way where the elapsed time between payments is indicative. In real life one would expect it is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
